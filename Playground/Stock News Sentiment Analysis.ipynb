{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "continuous-webmaster",
   "metadata": {},
   "source": [
    "Resources:\n",
    "- https://towardsdatascience.com/stock-news-sentiment-analysis-with-python-193d4b4378d4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "saving-publication",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import nltk\n",
    "# nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "faced-front",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import matplotlib.pyplot as plt\n",
    "from urllib.request import urlopen\n",
    "from urllib.request import Request\n",
    "from nltk.sentiment.sentiment_analyzer import SentimentAnalyzer\n",
    "\n",
    "# Parameters \n",
    "n = 15 #the # of article headlines displayed per ticker\n",
    "# tickers = ['AAPL', 'TSLA', 'AMZN']\n",
    "tickers = ['QQQ', 'TQQQ', 'SOXX', 'IGV', 'GOOGL', 'CPRX', 'SIRI', 'SPPI']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "attached-force",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Data\n",
    "finviz_url = 'https://finviz.com/quote.ashx?t='\n",
    "news_tables = {}\n",
    "\n",
    "for ticker in tickers:\n",
    "    url = finviz_url + ticker\n",
    "    req = Request(url=url,headers={'user-agent': 'my-app/0.0.1'}) \n",
    "    resp = urlopen(req)    \n",
    "    html = BeautifulSoup(resp, features=\"lxml\")\n",
    "    news_table = html.find(id='news-table')\n",
    "    news_tables[ticker] = news_table\n",
    "\n",
    "try:\n",
    "    for ticker in tickers:\n",
    "        df = news_tables[ticker]\n",
    "        df_tr = df.findAll('tr')\n",
    "    \n",
    "        # print ('\\n')\n",
    "        # print ('Recent News Headlines for {}: '.format(ticker))\n",
    "        \n",
    "        for i, table_row in enumerate(df_tr):\n",
    "            a_text = table_row.a.text\n",
    "            td_text = table_row.td.text\n",
    "            td_text = td_text.strip()\n",
    "            # print(a_text,'(',td_text,')')\n",
    "            if i == n-1:\n",
    "                break\n",
    "except KeyError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "romantic-service",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through the news\n",
    "parsed_news = []\n",
    "for file_name, news_table in news_tables.items():\n",
    "    for x in news_table.findAll('tr'):\n",
    "        text = x.a.get_text() \n",
    "        date_scrape = x.td.text.split()\n",
    "\n",
    "        if len(date_scrape) == 1:\n",
    "            time = date_scrape[0]\n",
    "            \n",
    "        else:\n",
    "            date = date_scrape[0]\n",
    "            time = date_scrape[1]\n",
    "\n",
    "        ticker = file_name.split('_')[0]\n",
    "        \n",
    "        parsed_news.append([ticker, date, time, text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "tracked-layout",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentiment Analysis\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "columns = ['Ticker', 'Date', 'Time', 'Headline']\n",
    "news = pd.DataFrame(parsed_news, columns=columns)\n",
    "scores = news['Headline'].apply(analyzer.polarity_scores).tolist()\n",
    "\n",
    "df_scores = pd.DataFrame(scores)\n",
    "news = news.join(df_scores, rsuffix='_right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "regional-miniature",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View Data \n",
    "news['Date'] = pd.to_datetime(news.Date).dt.date\n",
    "\n",
    "unique_ticker = news['Ticker'].unique().tolist()\n",
    "news_dict = {name: news.loc[news['Ticker'] == name] for name in unique_ticker}\n",
    "\n",
    "values = []\n",
    "for ticker in tickers: \n",
    "    dataframe = news_dict[ticker]\n",
    "    dataframe = dataframe.set_index('Ticker')\n",
    "    dataframe = dataframe.drop(columns = ['Headline'])\n",
    "    # print ('\\n')\n",
    "    # print (dataframe.head())\n",
    "    \n",
    "    mean = round(dataframe['compound'].mean(), 2)\n",
    "    values.append(mean)\n",
    "    \n",
    "df = pd.DataFrame(list(zip(tickers, values)), columns =['Ticker', 'Mean Sentiment']) \n",
    "df = df.set_index('Ticker')\n",
    "df = df.sort_values('Mean Sentiment', ascending=False)\n",
    "# print ('\\n')\n",
    "# print (df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "accepted-walter",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean Sentiment</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ticker</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SIRI</th>\n",
       "      <td>0.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TQQQ</th>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QQQ</th>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IGV</th>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CPRX</th>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SOXX</th>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GOOGL</th>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SPPI</th>\n",
       "      <td>-0.04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Mean Sentiment\n",
       "Ticker                \n",
       "SIRI              0.18\n",
       "TQQQ              0.12\n",
       "QQQ               0.09\n",
       "IGV               0.09\n",
       "CPRX              0.09\n",
       "SOXX              0.08\n",
       "GOOGL             0.07\n",
       "SPPI             -0.04"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "entire-superintendent",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
